{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"rqdMQKX1VgvW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6b35cdff-ee9c-458e-b25d-aad5b2e11841","executionInfo":{"status":"ok","timestamp":1718930360464,"user_tz":-420,"elapsed":26592,"user":{"displayName":"52.1442.Đỗ Đình Thắng","userId":"13916328329781526136"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install gradio==4.32.0\n","!pip3 install underthesea\n","import pandas as pd\n","import underthesea\n","import regex as re\n","from underthesea import word_tokenize"],"metadata":{"id":"0MumH379WUep","colab":{"base_uri":"https://localhost:8080/"},"outputId":"17b0fc0d-d812-4d07-f9e4-0fed65a1e159","executionInfo":{"status":"ok","timestamp":1718930417293,"user_tz":-420,"elapsed":56831,"user":{"displayName":"52.1442.Đỗ Đình Thắng","userId":"13916328329781526136"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gradio==4.32.0\n","  Downloading gradio-4.32.0-py3-none-any.whl (12.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio==4.32.0)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.32.0) (4.2.2)\n","Collecting fastapi (from gradio==4.32.0)\n","  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ffmpy (from gradio==4.32.0)\n","  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gradio-client==0.17.0 (from gradio==4.32.0)\n","  Downloading gradio_client-0.17.0-py3-none-any.whl (316 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.3/316.3 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx>=0.24.1 (from gradio==4.32.0)\n","  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio==4.32.0) (0.23.4)\n","Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==4.32.0) (6.4.0)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.32.0) (3.1.4)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.32.0) (2.1.5)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.32.0) (3.7.1)\n","Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.32.0) (1.25.2)\n","Collecting orjson~=3.0 (from gradio==4.32.0)\n","  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio==4.32.0) (24.1)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.32.0) (2.0.3)\n","Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.32.0) (9.4.0)\n","Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.32.0) (2.7.4)\n","Collecting pydub (from gradio==4.32.0)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Collecting python-multipart>=0.0.9 (from gradio==4.32.0)\n","  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.32.0) (6.0.1)\n","Collecting ruff>=0.2.2 (from gradio==4.32.0)\n","  Downloading ruff-0.4.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting semantic-version~=2.0 (from gradio==4.32.0)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Collecting tomlkit==0.12.0 (from gradio==4.32.0)\n","  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio==4.32.0) (0.12.3)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.32.0) (4.12.2)\n","Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.32.0) (2.0.7)\n","Collecting uvicorn>=0.14.0 (from gradio==4.32.0)\n","  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.17.0->gradio==4.32.0) (2023.6.0)\n","Collecting websockets<12.0,>=10.0 (from gradio-client==0.17.0->gradio==4.32.0)\n","  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.32.0) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.32.0) (4.19.2)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.32.0) (0.12.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio==4.32.0) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio==4.32.0) (2024.6.2)\n","Collecting httpcore==1.* (from httpx>=0.24.1->gradio==4.32.0)\n","  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio==4.32.0) (3.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio==4.32.0) (1.3.1)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio==4.32.0)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio==4.32.0) (3.15.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio==4.32.0) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio==4.32.0) (4.66.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.32.0) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.32.0) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.32.0) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.32.0) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.32.0) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.32.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==4.32.0) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==4.32.0) (2024.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio==4.32.0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio==4.32.0) (2.18.4)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio==4.32.0) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio==4.32.0) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio==4.32.0) (13.7.1)\n","Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio==4.32.0)\n","  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi->gradio==4.32.0)\n","  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n","Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio==4.32.0)\n","  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->gradio==4.32.0)\n","  Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n","Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio==4.32.0)\n","  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.32.0) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.32.0) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.32.0) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.32.0) (0.18.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==4.32.0) (1.16.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==4.32.0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==4.32.0) (2.16.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio==4.32.0) (1.2.1)\n","Collecting httptools>=0.5.0 (from uvicorn>=0.14.0->gradio==4.32.0)\n","  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn>=0.14.0->gradio==4.32.0)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.14.0->gradio==4.32.0)\n","  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.14.0->gradio==4.32.0)\n","  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio==4.32.0) (3.3.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==4.32.0) (0.1.2)\n","Building wheels for collected packages: ffmpy\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=8ec1a55bf5740e26923442529382095e290eaf73ba8a77fbcdf43fc38060d1ed\n","  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n","Successfully built ffmpy\n","Installing collected packages: pydub, ffmpy, websockets, uvloop, ujson, tomlkit, semantic-version, ruff, python-multipart, python-dotenv, orjson, httptools, h11, dnspython, aiofiles, watchfiles, uvicorn, starlette, httpcore, email_validator, httpx, gradio-client, fastapi-cli, fastapi, gradio\n","Successfully installed aiofiles-23.2.1 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 gradio-4.32.0 gradio-client-0.17.0 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 orjson-3.10.5 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 ruff-0.4.10 semantic-version-2.10.0 starlette-0.37.2 tomlkit-0.12.0 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-11.0.3\n","Collecting underthesea\n","  Downloading underthesea-6.8.3-py3-none-any.whl (20.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from underthesea) (8.1.7)\n","Collecting python-crfsuite>=0.9.6 (from underthesea)\n","  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from underthesea) (3.8.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from underthesea) (4.66.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from underthesea) (2.31.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from underthesea) (1.4.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from underthesea) (1.2.2)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from underthesea) (6.0.1)\n","Collecting underthesea-core==1.0.4 (from underthesea)\n","  Downloading underthesea_core-1.0.4-cp310-cp310-manylinux2010_x86_64.whl (657 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->underthesea) (2024.5.15)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (2024.6.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (1.25.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (1.11.4)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (3.5.0)\n","Installing collected packages: underthesea-core, python-crfsuite, underthesea\n","Successfully installed python-crfsuite-0.9.10 underthesea-6.8.3 underthesea-core-1.0.4\n","No module named 'fasttext'\n"]}]},{"cell_type":"code","source":["# Cài đặt một số hàm tiền xử lý văn bản cần thiết\n","# !pip3 install --user underthesea\n","# import regex as re\n","# from underthesea import word_tokenize\n","\n","uniChars = \"àáảãạâầấẩẫậăằắẳẵặèéẻẽẹêềếểễệđìíỉĩịòóỏõọôồốổỗộơờớởỡợùúủũụưừứửữựỳýỷỹỵÀÁẢÃẠÂẦẤẨẪẬĂẰẮẲẴẶÈÉẺẼẸÊỀẾỂỄỆĐÌÍỈĨỊÒÓỎÕỌÔỒỐỔỖỘƠỜỚỞỠỢÙÚỦŨỤƯỪỨỬỮỰỲÝỶỸỴÂĂĐÔƠƯ\"\n","unsignChars = \"aaaaaaaaaaaaaaaaaeeeeeeeeeeediiiiiooooooooooooooooouuuuuuuuuuuyyyyyAAAAAAAAAAAAAAAAAEEEEEEEEEEEDIIIOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUYYYYYAADOOU\"\n","\n","def loaddicchar():\n","    dic = {}\n","    char1252 = 'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ'.split(\n","        '|')\n","    charutf8 = \"à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ\".split(\n","        '|')\n","    for i in range(len(char1252)):\n","        dic[char1252[i]] = charutf8[i]\n","    return dic\n","dicchar = loaddicchar()\n","\n","# Hàm chuyển Unicode dựng sẵn về Unicde tổ hợp (phổ biến hơn)\n","def convert_unicode(txt):\n","    return re.sub(\n","        r'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ',\n","        lambda x: dicchar[x.group()], txt)\n","\n","bang_nguyen_am = [['a', 'à', 'á', 'ả', 'ã', 'ạ', 'a'],\n","                  ['ă', 'ằ', 'ắ', 'ẳ', 'ẵ', 'ặ', 'aw'],\n","                  ['â', 'ầ', 'ấ', 'ẩ', 'ẫ', 'ậ', 'aa'],\n","                  ['e', 'è', 'é', 'ẻ', 'ẽ', 'ẹ', 'e'],\n","                  ['ê', 'ề', 'ế', 'ể', 'ễ', 'ệ', 'ee'],\n","                  ['i', 'ì', 'í', 'ỉ', 'ĩ', 'ị', 'i'],\n","                  ['o', 'ò', 'ó', 'ỏ', 'õ', 'ọ', 'o'],\n","                  ['ô', 'ồ', 'ố', 'ổ', 'ỗ', 'ộ', 'oo'],\n","                  ['ơ', 'ờ', 'ớ', 'ở', 'ỡ', 'ợ', 'ow'],\n","                  ['u', 'ù', 'ú', 'ủ', 'ũ', 'ụ', 'u'],\n","                  ['ư', 'ừ', 'ứ', 'ử', 'ữ', 'ự', 'uw'],\n","                  ['y', 'ỳ', 'ý', 'ỷ', 'ỹ', 'ỵ', 'y']]\n","bang_ky_tu_dau = ['', 'f', 's', 'r', 'x', 'j']\n","\n","nguyen_am_to_ids = {}\n","\n","for i in range(len(bang_nguyen_am)):\n","    for j in range(len(bang_nguyen_am[i]) - 1):\n","        nguyen_am_to_ids[bang_nguyen_am[i][j]] = (i, j)\n","\n","def chuan_hoa_dau_tu_tieng_viet(word):\n","    if not is_valid_vietnam_word(word):\n","        return word\n","\n","    chars = list(word)\n","    dau_cau = 0\n","    nguyen_am_index = []\n","    qu_or_gi = False\n","    for index, char in enumerate(chars):\n","        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n","        if x == -1:\n","            continue\n","        elif x == 9:  # check qu\n","            if index != 0 and chars[index - 1] == 'q':\n","                chars[index] = 'u'\n","                qu_or_gi = True\n","        elif x == 5:  # check gi\n","            if index != 0 and chars[index - 1] == 'g':\n","                chars[index] = 'i'\n","                qu_or_gi = True\n","        if y != 0:\n","            dau_cau = y\n","            chars[index] = bang_nguyen_am[x][0]\n","        if not qu_or_gi or index != 1:\n","            nguyen_am_index.append(index)\n","    if len(nguyen_am_index) < 2:\n","        if qu_or_gi:\n","            if len(chars) == 2:\n","                x, y = nguyen_am_to_ids.get(chars[1])\n","                chars[1] = bang_nguyen_am[x][dau_cau]\n","            else:\n","                x, y = nguyen_am_to_ids.get(chars[2], (-1, -1))\n","                if x != -1:\n","                    chars[2] = bang_nguyen_am[x][dau_cau]\n","                else:\n","                    chars[1] = bang_nguyen_am[5][dau_cau] if chars[1] == 'i' else bang_nguyen_am[9][dau_cau]\n","            return ''.join(chars)\n","        return word\n","\n","    for index in nguyen_am_index:\n","        x, y = nguyen_am_to_ids[chars[index]]\n","        if x == 4 or x == 8:  # ê, ơ\n","            chars[index] = bang_nguyen_am[x][dau_cau]\n","            # for index2 in nguyen_am_index:\n","            #     if index2 != index:\n","            #         x, y = nguyen_am_to_ids[chars[index]]\n","            #         chars[index2] = bang_nguyen_am[x][0]\n","            return ''.join(chars)\n","\n","    if len(nguyen_am_index) == 2:\n","        if nguyen_am_index[-1] == len(chars) - 1:\n","            x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n","            chars[nguyen_am_index[0]] = bang_nguyen_am[x][dau_cau]\n","            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n","            # chars[nguyen_am_index[1]] = bang_nguyen_am[x][0]\n","        else:\n","            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n","            # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]\n","            x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n","            chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n","    else:\n","        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n","        # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]\n","        x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n","        chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n","        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[2]]]\n","        # chars[nguyen_am_index[2]] = bang_nguyen_am[x][0]\n","    return ''.join(chars)\n","\n","\n","def is_valid_vietnam_word(word):\n","    chars = list(word)\n","    nguyen_am_index = -1\n","    for index, char in enumerate(chars):\n","        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n","        if x != -1:\n","            if nguyen_am_index == -1:\n","                nguyen_am_index = index\n","            else:\n","                if index - nguyen_am_index != 1:\n","                    return False\n","                nguyen_am_index = index\n","    return True\n","\n","\n","def chuan_hoa_dau_cau_tieng_viet(sentence):\n","    \"\"\"\n","        Chuyển câu tiếng việt về chuẩn gõ dấu kiểu cũ.\n","        :param sentence:\n","        :return:\n","        \"\"\"\n","    sentence = sentence.lower()\n","    words = sentence.split()\n","    for index, word in enumerate(words):\n","        cw = re.sub(r'(^\\p{P}*)([p{L}.]*\\p{L}+)(\\p{P}*$)', r'\\1/\\2/\\3', word).split('/')\n","        # print(cw)\n","        if len(cw) == 3:\n","            cw[1] = chuan_hoa_dau_tu_tieng_viet(cw[1])\n","        words[index] = ''.join(cw)\n","    return ' '.join(words)\n","\n","def remove_html(txt):\n","    return re.sub(r'<[^>]*>', '', txt)"],"metadata":{"id":"cYhjcu7mWW2V","executionInfo":{"status":"ok","timestamp":1718930417965,"user_tz":-420,"elapsed":681,"user":{"displayName":"52.1442.Đỗ Đình Thắng","userId":"13916328329781526136"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["file_path = '/content/drive/MyDrive/AI - Trí tuệ nhân tạo/FINAL ASSIGNMENT/FinalDataset.txt'\n","with open(file_path, 'r', encoding='utf-8') as file:\n","    data = file.read()"],"metadata":{"id":"yAysDcy6Wj9e","executionInfo":{"status":"ok","timestamp":1718930418458,"user_tz":-420,"elapsed":498,"user":{"displayName":"52.1442.Đỗ Đình Thắng","userId":"13916328329781526136"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def text_preprocess(document):\n","    # xóa html code\n","    document = remove_html(document)\n","    # xóa xuống dòng\n","    document= document.replace('\\n', ' ')\n","    # chuẩn hóa unicode\n","    document = convert_unicode(document)\n","    # chuẩn hóa cách gõ dấu tiếng Việt\n","    document = chuan_hoa_dau_cau_tieng_viet(document)\n","    # tách từ\n","    document = word_tokenize(document, format=\"text\")\n","    # đưa về lower\n","    document = document.lower()\n","    # xóa các ký tự không cần thiết\n","    document = re.sub(r'[^\\s\\wáàảãạăắằẳẵặâấầẩẫậéèẻẽẹêếềểễệóòỏõọôốồổỗộơớờởỡợíìỉĩịúùủũụưứừửữựýỳỷỹỵđ_]',' ',document)\n","    # xóa khoảng trắng thừa\n","    document = re.sub(r'\\s+', ' ', document).strip()\n","    return document"],"metadata":{"id":"k5SYs2aIWtbp","executionInfo":{"status":"ok","timestamp":1718930418459,"user_tz":-420,"elapsed":4,"user":{"displayName":"52.1442.Đỗ Đình Thắng","userId":"13916328329781526136"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["document = text_preprocess(data)"],"metadata":{"id":"Vw3uuizwWvXx","executionInfo":{"status":"ok","timestamp":1718930497447,"user_tz":-420,"elapsed":78991,"user":{"displayName":"52.1442.Đỗ Đình Thắng","userId":"13916328329781526136"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["count = {}\n","for line in open('/content/drive/MyDrive/AI - Trí tuệ nhân tạo/FINAL ASSIGNMENT/FinalDataset.txt'):\n","  # print(f\"====>{line}\")\n","  key = line.split()[0]\n","  count[key] = count.get(key, 0) + 1\n","\n","for key in count:\n","    print(key, count[key])"],"metadata":{"id":"iqTtM3_2fGPi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718930497448,"user_tz":-420,"elapsed":36,"user":{"displayName":"52.1442.Đỗ Đình Thắng","userId":"13916328329781526136"}},"outputId":"be3498e0-83e0-4ecf-cfaf-359a4fc710fc"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Am_nhac 100\n","Am_thuc 101\n","Bat_dong_san 100\n","Bong_da 101\n","Chung_khoan 101\n","Du_lich 101\n","Gia_dinh 101\n","Giao_duc 101\n","Khong_gian_song 101\n","Lam_dep 101\n","My_thuat 91\n","Thoi_trang 91\n"]}]},{"cell_type":"code","source":["# Thống kê các word xuất hiện ở tất cả các nhãn\n","total_label = 12\n","vocab = {}\n","label_vocab = {}\n","for line in open('/content/drive/MyDrive/AI - Trí tuệ nhân tạo/FINAL ASSIGNMENT/FinalDataset.txt'):\n","    words = line.split()\n","    # lưu ý từ đầu tiên là nhãn\n","    label = words[0]\n","    if label not in label_vocab:\n","        label_vocab[label] = {}\n","    for word in words[1:]:\n","        label_vocab[label][word] = label_vocab[label].get(word, 0) + 1\n","        if word not in vocab:\n","            vocab[word] = set()\n","        vocab[word].add(label)\n","\n","count = {}\n","for word in vocab:\n","    if len(vocab[word]) == total_label:\n","        count[word] = min([label_vocab[x][word] for x in label_vocab])\n","\n","sorted_count = sorted(count, key=count.get, reverse=True)\n","for word in sorted_count[:100]:\n","    print(word, count[word])"],"metadata":{"id":"qNrGmxQAfeGl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718930497992,"user_tz":-420,"elapsed":549,"user":{"displayName":"52.1442.Đỗ Đình Thắng","userId":"13916328329781526136"}},"outputId":"55f73683-3014-49c5-c1f2-d0224d510afd"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["và 298\n","có 250\n","cho 222\n","của 220\n","với 220\n","là 214\n","một 187\n","không 146\n","các 141\n","được 134\n","những 117\n","trong 108\n","để 98\n","như 88\n","trên 82\n","cũng 77\n","nhiều 77\n","người 73\n","khi 72\n","từ 69\n","ra 68\n","sẽ 68\n","vào 66\n","này 66\n","lại 64\n","đã 60\n","rất 58\n","đến 57\n","chỉ 56\n","thể 56\n","ở 56\n","làm 54\n","phải 53\n","- 52\n","nhưng 51\n","thành 50\n","nên 45\n","mà 44\n","còn 43\n","bị 40\n","đó 36\n","về 32\n","thì 32\n","hơn 32\n","theo 32\n","hợp 31\n","bằng 31\n","gia 30\n","hiện 29\n","hai 29\n","cách 29\n","lên 29\n","đầu 28\n","cả 26\n","tiếp 25\n","phần 24\n","trở 24\n","cùng 24\n","đi 23\n","nước 23\n","gian 22\n","hình 22\n","thực 22\n","đều 22\n","nhà 22\n","vì 21\n","mới 21\n","nhất 21\n","vừa 21\n","công 20\n","đây 20\n","đồng 20\n","khác 19\n","đường 19\n","cần 19\n","hay 19\n","nào 19\n","ngày 19\n","qua 18\n","chính 18\n","quá 18\n","thường 18\n","sau 17\n","số 17\n","điều 17\n","thêm 17\n","thế 16\n","thời 16\n","thấy 16\n","tại 15\n","mặt 15\n","đủ 14\n","chọn 14\n","ngoài 14\n","việc 13\n","Một 13\n","do 13\n","hàng 13\n","từng 13\n","cầu 13\n"]}]},{"cell_type":"code","source":["# loại stopword khỏi dữ liệu\n","# lưu file dùng về sau\n","stopword = set()\n","with open('stopwords.txt', 'w') as fp:\n","    for word in sorted_count[:100]:\n","        stopword.add(word)\n","        fp.write(word + '\\n')\n","\n","def remove_stopwords(line):\n","    words = []\n","    for word in line.strip().split():\n","        if word not in stopword:\n","            words.append(word)\n","    return ' '.join(words)\n","\n","\n","with open('dataset.prep', 'w') as fp:\n","    for line in open('/content/drive/MyDrive/AI - Trí tuệ nhân tạo/FINAL ASSIGNMENT/FinalDataset.txt'):\n","        line = remove_stopwords(line)\n","        fp.write(line + '\\n')"],"metadata":{"id":"T0iWpH9LfmQN","executionInfo":{"status":"ok","timestamp":1718930498398,"user_tz":-420,"elapsed":412,"user":{"displayName":"52.1442.Đỗ Đình Thắng","userId":"13916328329781526136"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Chia tập train/test\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","test_percent = 0.3\n","\n","text = []\n","label = []\n","\n","for line in open('dataset.prep'):\n","    words = line.strip().split()\n","    label.append(words[0])\n","    text.append(' '.join(words[1:]))\n","\n","X_train, X_test, y_train, y_test = train_test_split(text, label, test_size=test_percent, random_state=42)\n","\n","# Lưu train/test data\n","# Giữ nguyên train/test để về sau so sánh các mô hình cho công bằng\n","with open('train.txt', 'w') as fp:\n","    for x, y in zip(X_train, y_train):\n","        fp.write('{} {}\\n'.format(y, x))\n","\n","with open('test.txt', 'w') as fp:\n","    for x, y in zip(X_test, y_test):\n","        fp.write('{} {}\\n'.format(y, x))\n","\n","# encode label\n","label_encoder = LabelEncoder()\n","label_encoder.fit(y_train)\n","print(list(label_encoder.classes_), '\\n')\n","y_train = label_encoder.transform(y_train)\n","y_test = label_encoder.transform(y_test)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wvfl68TwjvSp","outputId":"4b07614d-137e-4cd3-9f8d-2fd0bd2a8991","executionInfo":{"status":"ok","timestamp":1718930498399,"user_tz":-420,"elapsed":9,"user":{"displayName":"52.1442.Đỗ Đình Thắng","userId":"13916328329781526136"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["['Am_nhac', 'Am_thuc', 'Bat_dong_san', 'Bong_da', 'Chung_khoan', 'Du_lich', 'Gia_dinh', 'Giao_duc', 'Khong_gian_song', 'Lam_dep', 'My_thuat', 'Thoi_trang'] \n","\n"]}]},{"cell_type":"code","source":["MODEL_PATH = '/content/drive/MyDrive/AI - Trí tuệ nhân tạo/FINAL ASSIGNMENT/ML_modal'\n","\n","import os\n","if not os.path.exists(MODEL_PATH):\n","    os.makedirs(MODEL_PATH)"],"metadata":{"id":"vixurtIrCega","executionInfo":{"status":"ok","timestamp":1718930498400,"user_tz":-420,"elapsed":6,"user":{"displayName":"52.1442.Đỗ Đình Thắng","userId":"13916328329781526136"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["import pickle\n","import time\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import cross_val_score\n","# Khởi tạo pipeline\n","text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,1),\n","                                             max_df=0.8,\n","                                             max_features=None)),\n","                     ('tfidf', TfidfTransformer()),\n","                     ('clf', MultinomialNB())\n","                    ])\n","# Đánh giá mô hình bằng phương pháp cross-validation\n","scores = cross_val_score(text_clf, X_train, y_train, cv=4)\n","train_time = time.time() - start_time\n","print(f'Mean cross-validation accuracy: {np.mean(scores)}')\n","# Huấn luyện mô hình trên toàn bộ tập huấn luyện\n","text_clf = text_clf.fit(X_train, y_train)\n","# Lưu mô hình đã huấn luyện\n","pickle.dump(text_clf, open(os.path.join(MODEL_PATH, \"NaiveBayes.pkl\"), 'wb'))\n","# Tải lại mô hình và dự đoán trên tập kiểm tra\n","model = pickle.load(open(os.path.join(MODEL_PATH, \"NaiveBayes.pkl\"), 'rb'))\n","y_pred = model.predict(X_test)\n","# Đánh giá mô hình trên tập kiểm tra\n","print('Naive Bayes, Accuracy =', np.mean(y_pred == y_test))\n","# In báo cáo phân loại\n","nb_model = pickle.load(open(os.path.join(MODEL_PATH,\"NaiveBayes.pkl\"), 'rb'))\n","y_pred = nb_model.predict(X_test)\n","print(\"________________________________________________________________________________\")\n","print(classification_report(y_test, y_pred, target_names=list(label_encoder.classes_)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"jYrdOnmawbLr","executionInfo":{"status":"error","timestamp":1718930570653,"user_tz":-420,"elapsed":3450,"user":{"displayName":"52.1442.Đỗ Đình Thắng","userId":"13916328329781526136"}},"outputId":"bd89d906-ce62-4632-e0a3-531651791785"},"execution_count":13,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'start_time' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-92bd20ea4a53>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Đánh giá mô hình bằng phương pháp cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrain_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Mean cross-validation accuracy: {np.mean(scores)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Huấn luyện mô hình trên toàn bộ tập huấn luyện\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'start_time' is not defined"]}]},{"cell_type":"code","source":["import os\n","import time\n","import pickle\n","import numpy as np\n","from sklearn.svm import SVC\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n","from sklearn.model_selection import cross_val_score, train_test_split\n","from sklearn.metrics import classification_report\n","\n","\n","\n","\n","from sklearn.preprocessing import LabelEncoder\n","# Khởi tạo pipeline\n","text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,1),\n","                                             max_df=0.8,\n","                                             max_features=None)),\n","                     ('tfidf', TfidfTransformer()),\n","                     ('clf', SVC(gamma='scale'))\n","                    ])\n","# Đánh giá mô hình bằng phương pháp cross-validation\n","scores = cross_val_score(text_clf, X_train, y_train, cv=4)\n","print(f'Mean cross-validation accuracy: {np.mean(scores)}')\n","# Huấn luyện mô hình trên toàn bộ tập huấn luyện\n","text_clf = text_clf.fit(X_train, y_train)\n","# Lưu mô hình đã huấn luyện\n","pickle.dump(text_clf, open(os.path.join(MODEL_PATH, \"svm.pkl\"), 'wb'))\n","# Tải lại mô hình và dự đoán trên tập kiểm tra\n","model = pickle.load(open(os.path.join(MODEL_PATH, \"svm.pkl\"), 'rb'))\n","y_pred = model.predict(X_test)\n","# Đánh giá mô hình trên tập kiểm tra\n","print('SVM, Accuracy =', np.mean(y_pred == y_test))\n","# In báo cáo phân loại\n","nb_model = pickle.load(open(os.path.join(MODEL_PATH,\"svm.pkl\"), 'rb'))\n","y_pred = nb_model.predict(X_test)\n","print(classification_report(y_test, y_pred, target_names=list(label_encoder.classes_)))"],"metadata":{"id":"aAKox8SoRU52","executionInfo":{"status":"aborted","timestamp":1718930570653,"user_tz":-420,"elapsed":3,"user":{"displayName":"52.1442.Đỗ Đình Thắng","userId":"13916328329781526136"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Xem kết quả trên từng nhãn\n","from sklearn.metrics import classification_report\n","nb_model = pickle.load(open(os.path.join(MODEL_PATH,\"NaiveBayes.pkl\"), 'rb'))\n","y_pred = nb_model.predict(X_test)\n","print(classification_report(y_test, y_pred, target_names=list(label_encoder.classes_)))"],"metadata":{"id":"H61s-msj1dl6","executionInfo":{"status":"aborted","timestamp":1718930570654,"user_tz":-420,"elapsed":4,"user":{"displayName":"52.1442.Đỗ Đình Thắng","userId":"13916328329781526136"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Xem kết quả trên từng nhãn\n","from sklearn.metrics import classification_report\n","\n","nb_model = pickle.load(open(os.path.join(MODEL_PATH,\"LogisticRegression.pkl\"), 'rb'))\n","y_pred = nb_model.predict(X_test)\n","print(classification_report(y_test, y_pred, target_names=list(label_encoder.classes_)))"],"metadata":{"id":"CbtUjAcl1XDA","executionInfo":{"status":"aborted","timestamp":1718930570654,"user_tz":-420,"elapsed":4,"user":{"displayName":"52.1442.Đỗ Đình Thắng","userId":"13916328329781526136"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Xem kết quả trên từng nhãn\n","from sklearn.metrics import classification_report\n","\n","nb_model = pickle.load(open(os.path.join(MODEL_PATH,\"svm.pkl\"), 'rb'))\n","y_pred = nb_model.predict(X_test)\n","print(classification_report(y_test, y_pred, target_names=list(label_encoder.classes_)))"],"metadata":{"id":"2xtWWIlJ1RgR","executionInfo":{"status":"aborted","timestamp":1718930570654,"user_tz":-420,"elapsed":4,"user":{"displayName":"52.1442.Đỗ Đình Thắng","userId":"13916328329781526136"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","document = \"Chứng khoán những ngày gần đây thực sự là trao đảo. Ba phần tư cổ phiếu trên thị trường giảm giá, lực bán dâng cao liên tục đẩy thanh khoản vượt 35.500 tỷ đồng trong phiên VN-Index sụt hơn 19 điểm.\\\n","Dù tăng vượt 1.280 điểm vào hôm qua, VN-Index bị nhuộm đỏ ngay những phút đầu phiên giao dịch hôm nay, mất gần 8 điểm. Sau khoảng một tiếng, chỉ số này mới cải thiện lên tham chiếu, giằng co một lúc rồi lấy lại sắc xanh nhờ lực cầu tiếp ứng. Tuy nhiên áp lực chốt lời ở nhóm bluechip vẫn rất cao khiến chỉ số nhanh chóng rơi về dưới tham chiếu trước khi nghỉ trưa.\\\n","Sang buổi chiều, chỉ số đại diện sàn HoSE khoác sắc đỏ liên tục. Nửa đầu buổi, chỉ số này chủ yếu giằng co quanh 1.270 điểm.\\\n","Đến sau 14h, xu hướng bán tháo lan nhanh từ nhóm bluechip sang hàng loạt cổ phiếu. Chỉ số bất ngờ giảm một mạch về sát 1.250 điểm, tức thấp hơn tham chiếu khoảng 30 điểm. Tuy nhiên, thị trường nhanh chóng cải thiện trước khi bước vào phiên ATC.\\\n","VN-Index đóng cửa ở gần 1.262 điểm, giảm hơn 19 điểm so với hôm trước. Đây là phiên điều chỉnh mạnh nhất hơn một tháng qua\"\n","\n","document = text_preprocess(document)\n","document = remove_stopwords(document)\n","svm_model = pickle.load(open(os.path.join(MODEL_PATH,\"NaiveBayes.pkl\"), 'rb'))\n","label = svm_model.predict([document])\n","print('Predict label:', label_encoder.inverse_transform(label))"],"metadata":{"id":"aw-jO5DGHMqD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3f280e4b-9d83-48a2-c7d0-b4484ea18000","executionInfo":{"status":"ok","timestamp":1718930571574,"user_tz":-420,"elapsed":923,"user":{"displayName":"52.1442.Đỗ Đình Thắng","userId":"13916328329781526136"}}},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Predict label: ['Chung_khoan']\n"]}]},{"cell_type":"code","source":["import gradio as gr\n","\n","def predict_label(content):\n","  content = text_preprocess(content)\n","  content = remove_stopwords(content)\n","  svm_model = pickle.load(open(os.path.join(MODEL_PATH,\"NaiveBayes.pkl\"), 'rb'))\n","  label = svm_model.predict([content])\n","  return \"Bài báo thuộc chủ đề: \" + str(label_encoder.inverse_transform(label))\n","\n","demo = gr.Interface(fn=predict_label, inputs=\"text\", outputs=\"text\")\n","demo.launch()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":630},"id":"55lSufdjBI-U","executionInfo":{"status":"ok","timestamp":1718930582951,"user_tz":-420,"elapsed":11380,"user":{"displayName":"52.1442.Đỗ Đình Thắng","userId":"13916328329781526136"}},"outputId":"63d6aff4-02ef-4d48-8b36-4db2952dee03"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Running on public URL: https://97e74f8d047bf7ee16.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://97e74f8d047bf7ee16.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":[],"metadata":{"id":"M_7dHh2gPvwj"},"execution_count":null,"outputs":[]}]}